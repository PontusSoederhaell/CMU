{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe6FCxz_nTh"
      },
      "source": [
        "## Bash and Magic Commands\n",
        "\n",
        "Colab runs in a Linux environment, and you can access terminal commands with !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z11my8G9n2L"
      },
      "source": [
        "# Recitation 0G: Available Compute and Google Colab\n",
        "\n",
        "Google Colab is a Jupyter Notebook service that can be accessed directly in the browser.\n",
        "*   Also provides access to computing resources, including the Tesla T4 GPU\n",
        "*   To access more powerful GPUs, you can choose to pay for Google Colab Pro or Pro+ (https://colab.research.google.com/signup)\n",
        "\n",
        "To access Google Colab, just navigate to the link: https://colab.research.google.com/. You can also create a Google Colab notebook directly in your Google Drive.\n",
        "\n",
        "This recitation assumes basic knowledge of using Jupyter Notebooks, so please familiarize yourself with it if you haven't already.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eEvU-AIh_P7M"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # allows you to view and monitor your current GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YBa0XwT_559"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lVW4AIh_8t_"
      },
      "outputs": [],
      "source": [
        "!ls\n",
        "# !cd\n",
        "# !mkdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdaA_xXS_m-H"
      },
      "source": [
        "Below are some magic commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bCrGbW5Aac8"
      },
      "outputs": [],
      "source": [
        "# %time\n",
        "# %env\n",
        "# %matplotlib inline\n",
        "# %debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdYrPigbA4Y-"
      },
      "source": [
        "## Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx5hEQ_tA3zq",
        "outputId": "130165a6-89f5-4643-c7f0-a6e1a87fbb4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID58WV8UBWKI"
      },
      "source": [
        "### Utilizing Free GPU/TPU Resources\n",
        "#### Changing Runtime\n",
        "- Runtime > Change runtime type\n",
        "- Select GPU\n",
        "\n",
        "#### GPUs: Training Time of ResNet50\n",
        "- T4: 1x Speedup (Baseline)\n",
        "- A100: 10x Speedup (Comparing to T4)\n",
        "- TPU: TPU is a completely different architecture and require many training constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOSkRWpDB1vC"
      },
      "source": [
        "## Managing Your Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q-uJeZGB9Si"
      },
      "source": [
        "### Mounting to Google Drive\n",
        "You can mount to Google Drive, which will allow you to save files, even when your runtime ends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXlFSzUFBVhb",
        "outputId": "2ed8583d-efdb-4eee-b8f6-b6ede661d808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-axJR47CVVz"
      },
      "source": [
        "### Saving/Loading files - Model checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LL76X5rOAs8F"
      },
      "outputs": [],
      "source": [
        "# Example MLP\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, size):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.layers = []\n",
        "        for in_dim, out_dim in zip(size[:-2], size[1:-1]):\n",
        "          self.layers.extend([\n",
        "              nn.Linear(in_dim, out_dim),\n",
        "              nn.ReLU(),\n",
        "              nn.BatchNorm1d(out_dim),\n",
        "              nn.Dropout(0.5),\n",
        "          ])\n",
        "        self.layers.append(nn.Linear(size[-2], size[-1]))\n",
        "        self.model = nn.Sequential(*self.layers)\n",
        "        self.model.apply(self.init_param)\n",
        "\n",
        "    def init_param(self, param):\n",
        "      if type(param) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(param.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.model(x)\n",
        "\n",
        "model = MLP([40, 2048, 512, 256, 71])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lW7ejfbCbZ-"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/checkpoints\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/checkpoints/checkpoint.pt\"\n",
        "\n",
        "torch.save({\n",
        "  'epoch': 10,\n",
        "  'model_state_dict': model.state_dict(),\n",
        "  'loss': 0.001,\n",
        "}, MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk83lcff2A7z"
      },
      "source": [
        "### Managing Dataset\n",
        "\n",
        "Obtaining dataset\n",
        "- Kaggle Command\n",
        "- Manually uploading\n",
        "\n",
        "DO NOT directly store dataset in Google Drive, instead...\n",
        "- Download/uploading dataset every time\n",
        "- Move dataset from Google Drive into content folder\n",
        "- Connect to GCP or AWS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "APmdK5IXC9Gr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "     ---------------------------------------- 59.2/59.2 kB 3.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py): started\n",
            "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73261 sha256=6244ffa9def59cfecde8075085c27f05a5301cae18a63c3bd25945b2dee000f4\n",
            "  Stored in directory: c:\\users\\pontu\\appdata\\local\\pip\\cache\\wheels\\de\\f7\\d8\\c3902cacb7e62cb611b1ad343d7cc07f42f7eb76ae3a52f3d1\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/root/.kaggle/kaggle.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15160\\2278445092.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mkdir /root/.kaggle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/root/.kaggle/kaggle.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{\"username\":\"<KAGGLE USERNAME>\",\"key\":\"<API KEY>\"}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Put your kaggle username & key here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.kaggle/kaggle.json'"
          ]
        }
      ],
      "source": [
        "#downloads dataset from kaggle\n",
        "\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"<KAGGLE USERNAME>\",\"key\":\"<API KEY>\"}')\n",
        "    # Put your kaggle username & key here\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download -c 11785-sp23-intro-to-colab\n",
        "! unzip /content/competitions/11785-sp23-intro-to-colab/11785-sp23-intro-to-colab.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK1umNzC0zRI"
      },
      "source": [
        "### Restart session vs restart runtime\n",
        "\n",
        "\n",
        "Restart session\n",
        "- Runtime > Restart session\n",
        "- Clears all session variables\n",
        "\n",
        "Restart runtime\n",
        "- Runtime > Disconnect and delete runtime\n",
        "- Deletes session\n",
        "- Lose files in content folder\n",
        "- Switching GPUs will also delete current runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxfttZt83bzK"
      },
      "source": [
        "# Colab Pro\n",
        "\n",
        "- Longer session runtime, reducing risk of timeout\n",
        "- Priority access to GPU\n",
        "- Increased storage\n",
        "- Supposedly background execution\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
