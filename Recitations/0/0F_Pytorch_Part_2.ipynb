{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWkdpMhpvZmF"
      },
      "source": [
        "## Introduction to PyTorch\n",
        "\n",
        "Welcome to the introductory tutorial on PyTorch Part 2! This notebook will guide you through the basic concepts and functionalities of PyTorch, a popular deep learning framework. By the end of this notebook, you'll understand some basics on dataloaders/datasets, build simple neural networks, and train a model.\n",
        "\n",
        "## 1. Setting Up the Environment\n",
        "\n",
        "First, we need to install PyTorch. You can install it using pip. Run the following command in your terminal or in a code cell:\n",
        "\n",
        "```!pip install torch torchvision```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Sf_pUMvcp5",
        "outputId": "fbaf49a3-64d6-4a82-a542-455f2ac4aa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYDwWWYtv1v_"
      },
      "source": [
        "## 2. Importing PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WvtZvTpJv6jM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9fRukLONEy1",
        "outputId": "90d314d5-45ec-408d-baf4-10d923aa3ed8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsVjnEzg1WML"
      },
      "source": [
        "## Building a neural Network\n",
        "\n",
        "Now, let's build a simple neural network using PyTorch. We'll create a basic feedforward network to classify handwritten digits from the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lCpEHYQv1gEw"
      },
      "outputs": [],
      "source": [
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1=nn.Linear(28*28, 128)\n",
        "    self.fc2=nn.Linear(128,64)\n",
        "    self.fc3=nn.Linear(64,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=x.view(-1, 28*28)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net=SimpleNN().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKyYnuUs1hUY"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JD_0j93G1k60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
            "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "2.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd6vFqdD4SDd"
      },
      "source": [
        "## Defining the Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gOTSz60j4Yp8"
      },
      "outputs": [],
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R02AD1EV42CS"
      },
      "source": [
        "## Training the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YJ9DGKtw45zZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1, Batch 100] loss: 1.340\n",
            "[Epoch 1, Batch 200] loss: 0.575\n",
            "[Epoch 1, Batch 300] loss: 0.453\n",
            "[Epoch 1, Batch 400] loss: 0.371\n",
            "[Epoch 1, Batch 500] loss: 0.363\n",
            "[Epoch 1, Batch 600] loss: 0.334\n",
            "[Epoch 1, Batch 700] loss: 0.337\n",
            "[Epoch 1, Batch 800] loss: 0.279\n",
            "[Epoch 1, Batch 900] loss: 0.295\n",
            "[Epoch 1, Batch 1000] loss: 0.283\n",
            "[Epoch 1, Batch 1100] loss: 0.245\n",
            "[Epoch 1, Batch 1200] loss: 0.252\n",
            "[Epoch 1, Batch 1300] loss: 0.248\n",
            "[Epoch 1, Batch 1400] loss: 0.223\n",
            "[Epoch 1, Batch 1500] loss: 0.215\n",
            "[Epoch 1, Batch 1600] loss: 0.206\n",
            "[Epoch 1, Batch 1700] loss: 0.221\n",
            "[Epoch 1, Batch 1800] loss: 0.193\n",
            "[Epoch 2, Batch 100] loss: 0.178\n",
            "[Epoch 2, Batch 200] loss: 0.194\n",
            "[Epoch 2, Batch 300] loss: 0.173\n",
            "[Epoch 2, Batch 400] loss: 0.168\n",
            "[Epoch 2, Batch 500] loss: 0.174\n",
            "[Epoch 2, Batch 600] loss: 0.194\n",
            "[Epoch 2, Batch 700] loss: 0.165\n",
            "[Epoch 2, Batch 800] loss: 0.161\n",
            "[Epoch 2, Batch 900] loss: 0.150\n",
            "[Epoch 2, Batch 1000] loss: 0.140\n",
            "[Epoch 2, Batch 1100] loss: 0.152\n",
            "[Epoch 2, Batch 1200] loss: 0.159\n",
            "[Epoch 2, Batch 1300] loss: 0.148\n",
            "[Epoch 2, Batch 1400] loss: 0.142\n",
            "[Epoch 2, Batch 1500] loss: 0.134\n",
            "[Epoch 2, Batch 1600] loss: 0.146\n",
            "[Epoch 2, Batch 1700] loss: 0.132\n",
            "[Epoch 2, Batch 1800] loss: 0.122\n",
            "[Epoch 3, Batch 100] loss: 0.115\n",
            "[Epoch 3, Batch 200] loss: 0.105\n",
            "[Epoch 3, Batch 300] loss: 0.125\n",
            "[Epoch 3, Batch 400] loss: 0.133\n",
            "[Epoch 3, Batch 500] loss: 0.105\n",
            "[Epoch 3, Batch 600] loss: 0.113\n",
            "[Epoch 3, Batch 700] loss: 0.132\n",
            "[Epoch 3, Batch 800] loss: 0.139\n",
            "[Epoch 3, Batch 900] loss: 0.123\n",
            "[Epoch 3, Batch 1000] loss: 0.101\n",
            "[Epoch 3, Batch 1100] loss: 0.150\n",
            "[Epoch 3, Batch 1200] loss: 0.113\n",
            "[Epoch 3, Batch 1300] loss: 0.121\n",
            "[Epoch 3, Batch 1400] loss: 0.128\n",
            "[Epoch 3, Batch 1500] loss: 0.128\n",
            "[Epoch 3, Batch 1600] loss: 0.133\n",
            "[Epoch 3, Batch 1700] loss: 0.102\n",
            "[Epoch 3, Batch 1800] loss: 0.119\n",
            "[Epoch 4, Batch 100] loss: 0.095\n",
            "[Epoch 4, Batch 200] loss: 0.100\n",
            "[Epoch 4, Batch 300] loss: 0.097\n",
            "[Epoch 4, Batch 400] loss: 0.128\n",
            "[Epoch 4, Batch 500] loss: 0.093\n",
            "[Epoch 4, Batch 600] loss: 0.110\n",
            "[Epoch 4, Batch 700] loss: 0.091\n",
            "[Epoch 4, Batch 800] loss: 0.104\n",
            "[Epoch 4, Batch 900] loss: 0.103\n",
            "[Epoch 4, Batch 1000] loss: 0.100\n",
            "[Epoch 4, Batch 1100] loss: 0.092\n",
            "[Epoch 4, Batch 1200] loss: 0.096\n",
            "[Epoch 4, Batch 1300] loss: 0.081\n",
            "[Epoch 4, Batch 1400] loss: 0.075\n",
            "[Epoch 4, Batch 1500] loss: 0.094\n",
            "[Epoch 4, Batch 1600] loss: 0.095\n",
            "[Epoch 4, Batch 1700] loss: 0.091\n",
            "[Epoch 4, Batch 1800] loss: 0.089\n",
            "[Epoch 5, Batch 100] loss: 0.095\n",
            "[Epoch 5, Batch 200] loss: 0.064\n",
            "[Epoch 5, Batch 300] loss: 0.086\n",
            "[Epoch 5, Batch 400] loss: 0.094\n",
            "[Epoch 5, Batch 500] loss: 0.075\n",
            "[Epoch 5, Batch 600] loss: 0.088\n",
            "[Epoch 5, Batch 700] loss: 0.091\n",
            "[Epoch 5, Batch 800] loss: 0.075\n",
            "[Epoch 5, Batch 900] loss: 0.079\n",
            "[Epoch 5, Batch 1000] loss: 0.080\n",
            "[Epoch 5, Batch 1100] loss: 0.082\n",
            "[Epoch 5, Batch 1200] loss: 0.089\n",
            "[Epoch 5, Batch 1300] loss: 0.081\n",
            "[Epoch 5, Batch 1400] loss: 0.071\n",
            "[Epoch 5, Batch 1500] loss: 0.090\n",
            "[Epoch 5, Batch 1600] loss: 0.072\n",
            "[Epoch 5, Batch 1700] loss: 0.118\n",
            "[Epoch 5, Batch 1800] loss: 0.078\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5): #Loop over the dataset multiple time\n",
        "  running_loss=0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, lables=data\n",
        "    inputs, labels=inputs.to(device), lables.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs=net(inputs)\n",
        "    loss=criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss +=loss.item()\n",
        "    if i%100 ==99: #print every 100 miini_batches\n",
        "      print(f'[Epoch {epoch+1}, Batch {i+1}] loss: {running_loss/100:.3f}')\n",
        "      running_loss=0.0\n",
        "print('Finished Training')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd0LcvzL6zzk",
        "outputId": "ac249f85-fd89-4083-df55-42327761238d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.24%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PLGDVNM7cIF"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "Bravo! Just now, using PyTorch, you constructed and trained a basic neural network. In this notebook, we discussed:\n",
        "\n",
        "\n",
        "Build and work with tensors\n",
        "constructing a neural network\n",
        "Testing and educating the network\n",
        "Try changing the training parameters and network architecture to observe how it affects performance. Cheers to learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9swAlaM7t__"
      },
      "source": [
        "\n",
        "This notebook covers the fundamental steps needed to introduce PyTorch to students, providing a hands-on approach to understanding tensors, neural networks, and the training process. Adjust the complexity and depth based on your students' prior knowledge and the course objectives.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
